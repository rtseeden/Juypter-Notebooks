{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d0ZjbCiUVjKq",
        "outputId": "ad37de1e-8307-466a-9b22-c9d43860def0"
      },
      "source": [
        "import numpy as np\n",
        "import csv\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from random import random\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.metrics import confusion_matrix as CM\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "reader = csv.reader(open('/content/drive/MyDrive/Data/planning.csv', 'r'), delimiter=\",\")\n",
        "reader2 = csv.reader(open('/content/drive/MyDrive/Data/abalone.csv', 'r'), delimiter=\",\")\n",
        "\n",
        "def sample(M,p):\n",
        "  samples=np.zeros(M)\n",
        "  c=np.zeros(len(p))\n",
        "  sum=0\n",
        "  for i in range(len(p)):#This loop finds the cdf of the distribution\n",
        "    sum+=p[i]\n",
        "    c[i]=sum #cdf is the cummulation of the probabilities so we add the probabilities together \n",
        "  for i in range(M):\n",
        "    x=np.random.uniform(0,1)\n",
        "    for j in range(len(c)):\n",
        "      if x < c[j]: # determines which range the sample belongs in\n",
        "        samples[i]=j\n",
        "        break\n",
        "  return samples\n",
        "\n",
        "class adaboost:\n",
        "    def __init__(self, numClassifiers):\n",
        "      self.numClassifiers = numClassifiers\n",
        "      self.alphas = [None]*numClassifiers\n",
        "      self.h = [None]*numClassifiers\n",
        "    def fit(self, X, y):\n",
        "      #number samples and number of features\n",
        "      N, F= X.shape\n",
        "      weights= np.array([1/N for i in range(N)])\n",
        "      \n",
        "      for m in range(self.numClassifiers):\n",
        "        idx = sample(len(weights), weights)   \n",
        "        idx=idx.astype(int)\n",
        "        h = DecisionTreeClassifier(max_depth=2)\\\n",
        "                        .fit(X[idx],y[idx],sample_weight=weights).predict\n",
        "        \n",
        "        sum=0\n",
        "        for i in range(len(weights)):  \n",
        "          if (y[i] != h(X[i].reshape(1,-1))):\n",
        "            sum=sum+weights[i]\n",
        "              \n",
        "        error = sum\n",
        "              \n",
        "        alpha = 0.5 *np.log((1-error)/error)\n",
        "        #increase weight if we got the point wrong\n",
        "        for i in range(len(weights)):\n",
        "          if (y[i] != h(X[i].reshape(1,-1))):\n",
        "            weights[i]=weights[i]*np.exp(-1*alpha*1)\n",
        "          else:\n",
        "             weights[i]=weights[i]*np.exp(-1*alpha*0)\n",
        "    \n",
        "              \n",
        "        self.h[m] = h\n",
        "        self.alphas[m]=alpha\n",
        "\n",
        "    def predict(self,X):\n",
        "        y = 0\n",
        "        for m in range(self.numClassifiers):\n",
        "            h=self.h[m]\n",
        "            y += self.alphas[m]*h(X)\n",
        "        A = np.zeros(len(y))\n",
        "        for i in range(len(y)):\n",
        "          if y[i]!=0:\n",
        "            A[i]= abs(y[i])/y[i]\n",
        "          else:\n",
        "            A[i]=1\n",
        "        y = np.where(A==-1,-1,1)\n",
        "        return y\n",
        "       \n",
        "def compare(x,y):\n",
        "  clf = adaboost(numClassifiers=5)\n",
        "  clf.fit(x,y)\n",
        "  y_pred = clf.predict(x)\n",
        "  print(\"Accuracy of my AdaBoost: %0.2f %%\" % (100*sum(y_pred==y)/len(y)))\n",
        "  clf2 = AdaBoostClassifier(n_estimators=5)\n",
        "  clf2.fit(x,y)\n",
        "  y_pred2 = clf2.predict(x)\n",
        "  print(\"Accuracy of Sklearn: %0.2f %%\" % (100*sum(y_pred2==y)/len(y)))\n",
        "\n",
        "  \n",
        "a = list(reader)\n",
        "data = np.array(a).astype(float)\n",
        "x=data[:, 0:12] \n",
        "y=data[:,12].astype(int)\n",
        "y = np.where(y==0,-1,1)\n",
        "\n",
        "print(\"Planning Dataset:\")\n",
        "compare(x,y)\n",
        "\n",
        "a = list(reader2)\n",
        "data = np.array(a).astype(float)\n",
        "x=data[:, 0:8] \n",
        "y=data[:,8].astype(int)\n",
        "y = np.where(y==0,-1,1)\n",
        "\n",
        "print(\"Abalone Dataset:\")\n",
        "compare(x,y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Planning Dataset:\n",
            "Accuracy of my AdaBoost: 71.43 %\n",
            "Accuracy of Sklearn: 73.63 %\n",
            "Abalone Dataset:\n",
            "Accuracy of my AdaBoost: 82.38 %\n",
            "Accuracy of Sklearn: 82.93 %\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}